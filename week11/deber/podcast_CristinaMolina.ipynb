{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcz7Fqs2isgP"
      },
      "source": [
        "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
        "##### Nombre: Cristina Molina\n",
        "\n",
        "Objective:\n",
        "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Step 1: Import Libraries\n",
        "Import necessary libraries for data handling, text processing, and machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exSuLD4rh8-u",
        "outputId": "f40150f3-a1ab-496b-dbf6-67e369ac80ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importar bibliotecas necesarias para el manejo de datos, procesamiento de texto y aprendizaje automático\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Descargar recursos adicionales de NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emYkF0WXiqSC"
      },
      "source": [
        "Step 2: Load the Dataset\n",
        "Load the dataset of podcast transcripts.\n",
        "\n",
        "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2Np8-jC5imtI"
      },
      "outputs": [],
      "source": [
        "# Ruta al archivo ZIP que contiene el CSV\n",
        "ruta_al_zip = 'archive.zip'  # Asegúrate de que el archivo ZIP esté en el mismo directorio que este notebook\n",
        "\n",
        "# Nombre del archivo CSV dentro del ZIP\n",
        "nombre_archivo_csv = 'podcastdata_dataset.csv'\n",
        "\n",
        "# Extraer el archivo CSV del ZIP\n",
        "with zipfile.ZipFile(ruta_al_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall('../')  # Puedes especificar la ruta donde quieres extraer los archivos\n",
        "\n",
        "# Cargar el CSV en un DataFrame de pandas\n",
        "ruta_al_csv_extraido = '../' + nombre_archivo_csv\n",
        "dataset = pd.read_csv(ruta_al_csv_extraido)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk0S-MOxi07v"
      },
      "source": [
        "Step 3: Text Preprocessing\n",
        "\n",
        "Delete punctuation\n",
        "\n",
        "Delete stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OgwJrw_4i4MT"
      },
      "outputs": [],
      "source": [
        "# Función para preprocesar el texto\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Aplicar preprocesamiento al dataset\n",
        "dataset['texto_preprocesado'] = dataset['text'].apply(preprocess_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3rrm9r8jLi1"
      },
      "source": [
        "Step 4: Vector Space Representation - TF-IDF\n",
        "\n",
        "Create TF-IDF vector representations of the transcripts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5SJigKoAjNaJ"
      },
      "outputs": [],
      "source": [
        "# Crear la matriz TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(dataset['texto_preprocesado'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXET2GWqjQAh"
      },
      "source": [
        "Step 5: Vector Space Representation - BERT\n",
        "\n",
        "Create BERT vector representations of the transcripts using a pre-trained BERT model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxZ5bXeejQqZ",
        "outputId": "17bf37d5-1398-4b8e-b3ea-20c89d44794f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma de los embeddings BERT: torch.Size([319, 768])\n"
          ]
        }
      ],
      "source": [
        "# Cargar el tokenizador y el modelo BERT preentrenado\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Función para obtener embeddings BERT de un solo texto\n",
        "def get_bert_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "    return cls_embedding\n",
        "\n",
        "# Función para obtener embeddings BERT de forma paralela\n",
        "def get_bert_embeddings_parallel(texts):\n",
        "    embeddings = []\n",
        "    with ThreadPoolExecutor(max_workers=None) as executor:\n",
        "        for embedding in executor.map(get_bert_embeddings, texts):\n",
        "            embeddings.append(embedding)\n",
        "    return torch.cat([torch.tensor(embedding.numpy()) for embedding in embeddings], dim=0)\n",
        "\n",
        "# Obtener embeddings BERT para cada transcripción preprocesada en el dataset de forma paralela\n",
        "bert_embeddings = get_bert_embeddings_parallel(dataset['texto_preprocesado'])\n",
        "\n",
        "# Mostrar la forma de los embeddings\n",
        "print(f'Forma de los embeddings BERT: {bert_embeddings.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VhWbYSkjUUp"
      },
      "source": [
        "Step 6: Query Processing\n",
        "\n",
        "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gBHJ_AnWjUwx"
      },
      "outputs": [],
      "source": [
        "# Función para procesar consultas y calcular similitud utilizando TF-IDF y BERT\n",
        "def procesar_consulta(query, tfidf_matrix, bert_embeddings, dataset):\n",
        "    # Calcular similitud utilizando TF-IDF\n",
        "    tfidf_scores = tfidf_matrix @ tfidf_vectorizer.transform([query]).T\n",
        "\n",
        "    # Calcular embeddings BERT para la consulta\n",
        "    query_embedding = get_bert_embeddings(preprocess_text(query))\n",
        "\n",
        "    # Calcular similitud utilizando BERT\n",
        "    bert_scores = torch.cosine_similarity(query_embedding, bert_embeddings, dim=1)\n",
        "\n",
        "    # Obtener índices ordenados por similitud descendente para TF-IDF y BERT\n",
        "    tfidf_indices = tfidf_scores.toarray().flatten().argsort()[::-1]\n",
        "    bert_indices = bert_scores.argsort(descending=True)\n",
        "\n",
        "    # Obtener títulos de episodios basados en los índices ordenados\n",
        "    tfidf_results = dataset.iloc[tfidf_indices]['title']\n",
        "    bert_results = dataset.iloc[bert_indices]['title']\n",
        "\n",
        "    return tfidf_results, bert_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k4PKTHyjWXo"
      },
      "source": [
        "Step 7: Retrieve and Compare Results\n",
        "\n",
        "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fKM02ODjYOa",
        "outputId": "d30ffa9e-4386-40b8-934f-91c73b7a83ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados de TF-IDF:\n",
            "126    Conversations, Ideas, Love, Freedom & The Joe ...\n",
            "305    Comedy, Sentient Robots, Suffering, Love & Bur...\n",
            "122    Origin of Life, Humans, Ideas, Suffering, and ...\n",
            "163    Sleep, Dreams, Creativity & the Limits of the ...\n",
            "170                                              Bitcoin\n",
            "102                      Artificial General Intelligence\n",
            "103               Computer Architecture and Data Storage\n",
            "104                                   Edison of Medicine\n",
            "105         Neuroscience, Psychology, and AI at DeepMind\n",
            "106                 Suffering in Humans, Animals, and AI\n",
            "Name: title, dtype: object\n",
            "\n",
            "Resultados de BERT:\n",
            "296                   Marxism, Capitalism, and Economics\n",
            "302    Doom, Quake, VR, AGI, Programming, Video Games...\n",
            "137           Ayn Rand and the Philosophy of Objectivism\n",
            "168           Solving Martial Arts from First Principles\n",
            "284                                      Imagine Dragons\n",
            "219    Cyc and the Quest to Solve Common Sense Reason...\n",
            "272                             Legendary Music Producer\n",
            "268    Space Colonization and Self-Assembling Space M...\n",
            "162    Difficult Conversations, Freedom of Speech, an...\n",
            "177                  Ayn Rand, Human Nature, and Anarchy\n",
            "Name: title, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Función para recuperar los resultados superiores basados en la similitud\n",
        "def retrieve_results(query, tfidf_matrix, bert_embeddings, dataset):\n",
        "    tfidf_results, bert_results = procesar_consulta(query, tfidf_matrix, bert_embeddings, dataset)\n",
        "\n",
        "    print(\"Resultados de TF-IDF:\")\n",
        "    print(tfidf_results.head(10))  # Mostrar los 10 mejores resultados\n",
        "\n",
        "    print(\"\\nResultados de BERT:\")\n",
        "    print(bert_results.head(10))  # Mostrar los 10 mejores resultados\n",
        "\n",
        "# Probar el sistema con una consulta de ejemplo\n",
        "query = \"Duncan\"\n",
        "retrieve_results(query, tfidf_matrix, bert_embeddings, dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WUgtwE-jZyA"
      },
      "source": [
        "Step 8: Test the IR System\n",
        "\n",
        "Test the system with a sample query.\n",
        "\n",
        "Retrieve and display the top results using both TF-IDF and BERT representations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-60aycvjbUf",
        "outputId": "1716ac91-2386-4895-d9c5-fce5bf274e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados de TF-IDF:\n",
            "2                                AI in the Age of Reason\n",
            "61      Concepts, Analogies, Common Sense & Future of AI\n",
            "119                             Measures of Intelligence\n",
            "38          Keras, Deep Learning, and the Progress of AI\n",
            "295    IQ Tests, Human Intelligence, and Group Differ...\n",
            "12                           Brains, Minds, and Machines\n",
            "0                                               Life 3.0\n",
            "91     Square, Cryptocurrency, and Artificial Intelli...\n",
            "1                                          Consciousness\n",
            "75      Universal Artificial Intelligence, AIXI, and AGI\n",
            "Name: title, dtype: object\n",
            "\n",
            "Resultados de BERT:\n",
            "296                   Marxism, Capitalism, and Economics\n",
            "168           Solving Martial Arts from First Principles\n",
            "3                                          Deep Learning\n",
            "223    Neuromorphic Computing and Optoelectronic Inte...\n",
            "256    Dark Matter of Intelligence and Self-Supervise...\n",
            "286    Reality is an Illusion – How Evolution Hid the...\n",
            "165    Deep Work, Focus, Productivity, Email, and Soc...\n",
            "268    Space Colonization and Self-Assembling Space M...\n",
            "137           Ayn Rand and the Philosophy of Objectivism\n",
            "162    Difficult Conversations, Freedom of Speech, an...\n",
            "Name: title, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Consulta de ejemplo para probar el sistema\n",
        "query = \"Artificial Intelligence\"\n",
        "\n",
        "# Recuperar y mostrar los resultados superiores utilizando TF-IDF y BERT\n",
        "retrieve_results(query, tfidf_matrix, bert_embeddings, dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_jNYMThjeXI"
      },
      "source": [
        "Step 9: Compare Results\n",
        "\n",
        "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
        "\n",
        "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-uw9yt0l8mL",
        "outputId": "624d2d2d-9477-4845-bbc3-fa9baed791b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparación de Resultados para la consulta: Artificial Intelligence\n",
            "\n",
            "Resultados de TF-IDF:\n",
            "2                                AI in the Age of Reason\n",
            "61      Concepts, Analogies, Common Sense & Future of AI\n",
            "119                             Measures of Intelligence\n",
            "38          Keras, Deep Learning, and the Progress of AI\n",
            "295    IQ Tests, Human Intelligence, and Group Differ...\n",
            "12                           Brains, Minds, and Machines\n",
            "0                                               Life 3.0\n",
            "91     Square, Cryptocurrency, and Artificial Intelli...\n",
            "1                                          Consciousness\n",
            "75      Universal Artificial Intelligence, AIXI, and AGI\n",
            "Name: title, dtype: object\n",
            "\n",
            "Resultados de BERT:\n",
            "296                   Marxism, Capitalism, and Economics\n",
            "168           Solving Martial Arts from First Principles\n",
            "3                                          Deep Learning\n",
            "223    Neuromorphic Computing and Optoelectronic Inte...\n",
            "256    Dark Matter of Intelligence and Self-Supervise...\n",
            "286    Reality is an Illusion – How Evolution Hid the...\n",
            "165    Deep Work, Focus, Productivity, Email, and Soc...\n",
            "268    Space Colonization and Self-Assembling Space M...\n",
            "137           Ayn Rand and the Philosophy of Objectivism\n",
            "162    Difficult Conversations, Freedom of Speech, an...\n",
            "Name: title, dtype: object\n",
            "\n",
            "Observaciones:\n",
            "TF-IDF:\n",
            "- Ventajas: Rápido de calcular, adecuado para términos frecuentes.\n",
            "- Desventajas: Puede no capturar bien el contexto semántico.\n",
            "BERT:\n",
            "- Ventajas: Captura el contexto semántico, puede manejar variaciones en el lenguaje.\n",
            "- Desventajas: Más lento de calcular, requiere más recursos computacionales.\n"
          ]
        }
      ],
      "source": [
        "# Análisis y comparación de resultados\n",
        "# Esta celda está destinada a documentar las observaciones sobre las fortalezas y debilidades de cada método basado en los resultados de recuperación\n",
        "\n",
        "def compare_results(query, tfidf_matrix, bert_embeddings, dataset):\n",
        "    tfidf_results, bert_results = procesar_consulta(query, tfidf_matrix, bert_embeddings, dataset)\n",
        "\n",
        "    print(\"Comparación de Resultados para la consulta:\", query)\n",
        "    print(\"\\nResultados de TF-IDF:\")\n",
        "    print(tfidf_results.head(10))  # Mostrar los 10 mejores resultados\n",
        "\n",
        "    print(\"\\nResultados de BERT:\")\n",
        "    print(bert_results.head(10))  # Mostrar los 10 mejores resultados\n",
        "\n",
        "    # Documentar observaciones\n",
        "    print(\"\\nObservaciones:\")\n",
        "    print(\"TF-IDF:\")\n",
        "    print(\"- Ventajas: Rápido de calcular, adecuado para términos frecuentes.\")\n",
        "    print(\"- Desventajas: Puede no capturar bien el contexto semántico.\")\n",
        "\n",
        "    print(\"BERT:\")\n",
        "    print(\"- Ventajas: Captura el contexto semántico, puede manejar variaciones en el lenguaje.\")\n",
        "    print(\"- Desventajas: Más lento de calcular, requiere más recursos computacionales.\")\n",
        "\n",
        "# Probar la comparación con una consulta de ejemplo\n",
        "compare_results(\"Artificial Intelligence\", tfidf_matrix, bert_embeddings, dataset)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
