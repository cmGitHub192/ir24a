{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7ffbb9-2ffc-496d-892c-ec3aa44f7f02",
   "metadata": {},
   "source": [
    "Nombre: Cristina Molina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aea0f6-db64-4920-9122-7f76102c391a",
   "metadata": {},
   "source": [
    "# Instalación de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ce8e6f-2a96-4fbe-b99e-ecf398ebfa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (2024.4.28)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb271d6-704d-4d81-9c67-64c4cdd15fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814289a-285b-4301-856b-546526243039",
   "metadata": {},
   "source": [
    "# Prepocesamiento de la Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45927e6d-40ab-4474-b4a6-d564e7446e18",
   "metadata": {},
   "source": [
    "En esta sección, llevamos a cabo el preprocesamiento del texto contenido en archivos de texto plano. Este preprocesamiento implica una serie de pasos para limpiar y estructurar el texto de manera que sea más adecuado para su posterior análisis. Los pasos específicos incluyen:\r\n",
    "\r\n",
    "1. **Lectura de Archivos**: Utilizamos la función `preprocess_text` para leer el contenido de un archivo dado y cargarlo en una variable de texto.\r\n",
    "\r\n",
    "2. **Conversión a Minúsculas**: Para asegurarnos de que no haya ambigüedades en el análisis, convertimos todo el texto a minúsculas usando `text.lower()`.\r\n",
    "\r\n",
    "3. **Tokenización**: Dividimos el texto en palabras o \"tokens\" utilizando expresiones regulares. La función `re.findall(r'\\b\\w+\\b', text)` busca todas las secuencias de caracteres alfanuméricos y las trata como tokens. Esto nos permite trabajar con unidades significativas de texto en lugar de caracteres individuales.\r\n",
    "\r\n",
    "4. **Eliminación de Duplicados**: En algunos casos, un mismo token puede aparecer múltiples veces en un archivo o en varios archivos. Para evitar redundancias y mejorar la eficiencia del análisis, eliminamos los duplicados de la lista de tokens utilizando `list(dict.fromkeys(tokens))`.\r\n",
    "\r\n",
    "5. **Aplicación de Stemming**: Finalmente, aplicamos stemming a cada token para reducir las palabras a su forma raíz o \"stem\". El stemmer utilizado en este caso es el SnowballStemmer del paquete NLTK. Esto nos permite tratar palabras con la misma raíz como si fueran la misma palabra, lo que simplifica el análisis y la búsqueda.\r\n",
    "\r\n",
    "El resultado de este proceso es una lista de tokens procesados y normalizados que están listos para ser utilizados en la construcción del índice invertido y otros análisis posteriores.\r\n",
    "\r\n",
    "Este preprocesamiento es fundamental en el procesamiento de lenguaje natural, ya que ayuda a reducir la complejidad del texto y a extraer las características más relevantes para su análisis.\r\n",
    "a su análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423de5cc-27ac-4405-893c-0ec887c2c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def preprocess_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Convertir el texto a minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # Dividir el texto en tokens (palabras)\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "    # Eliminar duplicados de la lista de tokens\n",
    "    tokens = list(dict.fromkeys(tokens))\n",
    "\n",
    "    # Inicializar el stemmer\n",
    "    stemmer = SnowballStemmer('english')\n",
    "\n",
    "    # Aplicar stemming a cada token\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return stemmed_tokens\n",
    "\n",
    "# Directorio donde se encuentran los archivos TXT\n",
    "directory = 'Data'\n",
    "\n",
    "# Lista para almacenar los tokens procesados de todos los archivos\n",
    "all_tokens = []\n",
    "\n",
    "# Procesar cada archivo en el directorio\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        tokens = preprocess_text(file_path)\n",
    "        all_tokens.extend(tokens)\n",
    "\n",
    "# Eliminar duplicados de la lista de tokens de todos los archivos\n",
    "all_tokens = list(dict.fromkeys(all_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38432f0c-19e5-4aa4-9b0a-2b9c47a55099",
   "metadata": {},
   "source": [
    "# Creación del Índice Invertido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2810c-e581-439d-8172-5fd9bfd66b7d",
   "metadata": {},
   "source": [
    "\r\n",
    "En esta sección, construimos el índice invertido a partir de los tokens procesados de los archivos de texto. El índice invertido es una estructura de datos que asigna cada término (o token) a la lista de documentos en los que aparece. Los pasos específicos para construir el índice invertido incluyen:\r\n",
    "\r\n",
    "1. **Lectura de Archivos**: Iteramos sobre todos los archivos de texto en el directorio especificado y extraemos los tokens procesados de cada archivo utilizando la función `preprocess_text`.\r\n",
    "\r\n",
    "2. **Construcción del Índice**: Para cada token procesado, verificamos si ya está presente en el índice invertido. Si no está presente, lo añadimos como una nueva entrada en el índice con un conjunto vacío de documentos asociados. Luego, agregamos el nombre del archivo actual al conjunto de documentos asociados con el token.\r\n",
    "\r\n",
    "3. **Creación del DataFrame**: Utilizamos la estructura de datos DataFrame de la biblioteca pandas para representar el índice invertido. Creamos un DataFrame donde las filas representan los términos y las columnas representan los nombres de los archivos. Inicializamos todas las celdas del DataFrame con ceros.\r\n",
    "\r\n",
    "4. **Asignación de Valores**: Recorremos el índice invertido y asignamos un valor de 1 a las celdas correspondientes en el DataFrame donde el término aparece en un archivo específico. Esto nos da una representación binaria del índice invertido, donde un valor de 1 indica la presencia del término en un archivo y un valor de 0 indica lo contrario.\r\n",
    "\r\n",
    "5. **Guardado en Archivo CSV**: Finalmente, guardamos el DataFrame del índice invertido en un archivo CSV para su posterior uso y análisis.\r\n",
    "\r\n",
    "El resultado es un índice invertido completo que mapea cada término a los documentos en los que aparece, proporcionando una forma eficiente de buscar y recuperar información relevante a partir de los términos de búsqueda.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba0253f-6035-49b2-aa95-570ae91a45b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame del Índice Invertido:\n",
      "               pg100.txt  pg10676.txt  pg1080.txt  pg10907.txt  pg11.txt  \\\n",
      "the                    1            1           1            1         1   \n",
      "project                1            1           1            1         1   \n",
      "gutenberg              1            1           1            1         1   \n",
      "ebook                  1            1           1            1         1   \n",
      "of                     1            1           1            1         1   \n",
      "...                  ...          ...         ...          ...       ...   \n",
      "quixano                0            0           0            0         0   \n",
      "quixana                0            0           0            0         0   \n",
      "p74b                   0            0           0            0         0   \n",
      "tordesillesqu          0            0           0            0         0   \n",
      "p74e                   0            0           0            0         0   \n",
      "\n",
      "               pg1184.txt  pg120.txt  pg1232.txt  pg12582.txt  pg1259.txt  \\\n",
      "the                     1          1           1            1           1   \n",
      "project                 1          1           1            1           1   \n",
      "gutenberg               1          1           1            1           1   \n",
      "ebook                   1          1           1            1           1   \n",
      "of                      1          1           1            1           1   \n",
      "...                   ...        ...         ...          ...         ...   \n",
      "quixano                 0          0           0            0           0   \n",
      "quixana                 0          0           0            0           0   \n",
      "p74b                    0          0           0            0           0   \n",
      "tordesillesqu           0          0           0            0           0   \n",
      "p74e                    0          0           0            0           0   \n",
      "\n",
      "               ...  pg73448.txt  pg7370.txt  pg74.txt  pg76.txt  pg768.txt  \\\n",
      "the            ...            1           1         1         1          1   \n",
      "project        ...            1           1         1         1          1   \n",
      "gutenberg      ...            1           1         1         1          1   \n",
      "ebook          ...            1           1         1         1          1   \n",
      "of             ...            1           1         1         1          1   \n",
      "...            ...          ...         ...       ...       ...        ...   \n",
      "quixano        ...            0           0         0         0          0   \n",
      "quixana        ...            0           0         0         0          0   \n",
      "p74b           ...            0           0         0         0          0   \n",
      "tordesillesqu  ...            0           0         0         0          0   \n",
      "p74e           ...            0           0         0         0          0   \n",
      "\n",
      "               pg84.txt  pg844.txt  pg8800.txt  pg98.txt  pg996.txt  \n",
      "the                   1          1           1         1          1  \n",
      "project               1          1           1         1          1  \n",
      "gutenberg             1          1           1         1          1  \n",
      "ebook                 1          1           1         1          1  \n",
      "of                    1          1           1         1          1  \n",
      "...                 ...        ...         ...       ...        ...  \n",
      "quixano               0          0           0         0          1  \n",
      "quixana               0          0           0         0          1  \n",
      "p74b                  0          0           0         0          1  \n",
      "tordesillesqu         0          0           0         0          1  \n",
      "p74e                  0          0           0         0          1  \n",
      "\n",
      "[179423 rows x 98 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def construct_inverted_index(directory):\n",
    "    inverted_index = {}\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        tokens = preprocess_text(file_path)\n",
    "        \n",
    "        for token in tokens:  \n",
    "            if token not in inverted_index:\n",
    "                inverted_index[token] = set()\n",
    "            inverted_index[token].add(file)\n",
    "    \n",
    "    df = pd.DataFrame(index=inverted_index.keys(), columns=files)\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    for token, files in inverted_index.items():\n",
    "        for file in files:\n",
    "            df.at[token, file] = 1\n",
    "    \n",
    "    df.to_csv('inverted_index.csv')\n",
    "    \n",
    "    return df\n",
    "\n",
    "directory = 'Data'\n",
    "\n",
    "indice_invertido_df = construct_inverted_index(directory)  # Pasa el argumento 'directory' aquí\n",
    "\n",
    "print(\"DataFrame del Índice Invertido:\")\n",
    "print(indice_invertido_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e67a1-b8d0-42f9-8fe7-b1914ffbb025",
   "metadata": {},
   "source": [
    "# Ejemplo de Uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c17315-10a1-45c6-a522-1188d549a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para la palabra 'protectress':\n",
      "pg100.txt      1\n",
      "pg2600.txt     1\n",
      "pg41445.txt    1\n",
      "pg59468.txt    1\n",
      "pg84.txt       1\n",
      "Name: protectress, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el índice invertido desde el archivo CSV\n",
    "indice_invertido_df = pd.read_csv('inverted_index.csv', index_col=0)\n",
    "\n",
    "def buscar_palabra_en_indice(palabra):\n",
    "    palabra = palabra.lower()  # Convertir la palabra a minúsculas para que coincida con el formato en el DataFrame\n",
    "    if palabra in indice_invertido_df.index:\n",
    "        pd.set_option('display.max_rows', None)  # Mostrar todas las filas\n",
    "        pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
    "        resultados = indice_invertido_df.loc[palabra]\n",
    "        print(\"Resultados para la palabra '{}':\".format(palabra))\n",
    "        print(resultados[resultados > 0])  # Mostrar solo los libros donde la palabra aparece al menos una vez\n",
    "    else:\n",
    "        print(\"La palabra '{}' no se encuentra en ningún libro.\".format(palabra))\n",
    "\n",
    "# Ejemplo de uso:\n",
    "buscar_palabra_en_indice(\"protectress\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8d10a-1e8a-49f6-a7ed-5cab86ab6401",
   "metadata": {},
   "source": [
    "# Implementing Boolean Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297cc230-c7de-4f14-a91d-048c50a4a095",
   "metadata": {},
   "source": [
    "### Descripción\r\n",
    "Esta función realiza una búsqueda booleana en un índice invertido representado por un DataFrame de pandas. Permite realizar consultas con los operadores booleanos AND, OR y NOT.\r\n",
    "\r\n",
    "### Parámetros\r\n",
    "- `query` (str): La consulta booleana que se va a realizar.\r\n",
    "- `inverted_index_df` (DataFrame): El DataFrame que contiene el índice invertido.\r\n",
    "\r\n",
    "### Returns\r\n",
    "- result (set): Un conjunto de nombres de archivos que cumplen con la consulta booleana.\r\n",
    "\r\n",
    "### Comportamiento\r\n",
    "La función divide la consulta en partes utilizando el método split(). Luego, utiliza un bucle while para iterar sobre cada parte de la consulta.\r\n",
    "- Si la parte actual es 'AND', realiza una intersección entre los resultados de las operaciones anteriores y los resultados de la operación actual.\r\n",
    "- Si la parte actual es 'OR', realiza una unión entre los resultados de las operaciones anteriores y los resultados de la operación actual.\r\n",
    "- Si la parte actual es 'NOT', realiza una diferencia entre los resultados de las operaciones anteriores y los resultados de la operación actual.\r\n",
    "- Si la parte actual no es un operador booleano, busca en el índice invertido y devuelve los archivos asociados a esa palabra.\r\n",
    "\r\n",
    "Finalmente, la función devuelve un conjunto de nombres de archivos que cumplen con la consulta booleana.\n",
    "### Ejemplo de Uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0786357-bd2d-44b9-98a2-fce505a7810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos que cumplen con la consulta:\n",
      "{'pg43.txt', 'pg1259.txt', 'pg2814.txt', 'pg5197.txt', 'pg98.txt', 'pg52882.txt', 'pg10907.txt', 'pg1998.txt', 'pg18893.txt', 'pg67098.txt', 'pg55.txt', 'pg1232.txt', 'pg64317.txt', 'pg46.txt', 'pg16389.txt', 'pg16.txt', 'pg47312.txt', 'pg45540.txt', 'pg2641.txt', 'pg2160.txt', 'pg52281.txt', 'pg145.txt', 'pg1400.txt', 'pg2542.txt', 'pg7370.txt', 'pg47629.txt', 'pg1342.txt', 'pg26073.txt', 'pg20228.txt', 'pg6761.txt', 'pg67979.txt', 'pg41070.txt', 'pg408.txt', 'pg42933.txt', 'pg27827.txt', 'pg11.txt', 'pg41445.txt', 'pg768.txt', 'pg6130.txt', 'pg996.txt', 'pg2554.txt', 'pg44388.txt', 'pg21012.txt', 'pg45.txt', 'pg205.txt', 'pg514.txt', 'pg73444.txt', 'pg25344.txt', 'pg345.txt', 'pg844.txt', 'pg37106.txt', 'pg45848.txt', 'pg30254.txt', 'pg73447.txt', 'pg28054.txt', 'pg4300.txt', 'pg29728.txt', 'pg44837.txt', 'pg61419.txt', 'pg219.txt', 'pg1513.txt', 'pg2600.txt', 'pg50038.txt', 'pg2591.txt', 'pg1080.txt', 'pg244.txt', 'pg59469.txt', 'pg35899.txt', 'pg394.txt', 'pg8800.txt', 'pg3207.txt', 'pg84.txt', 'pg2701.txt', 'pg48191.txt', 'pg10676.txt', 'pg1184.txt', 'pg21700.txt', 'pg1260.txt', 'pg76.txt', 'pg600.txt', 'pg174.txt', 'pg5200.txt', 'pg6593.txt', 'pg1661.txt', 'pg73442.txt', 'pg59468.txt', 'pg100.txt', 'pg73448.txt', 'pg1952.txt', 'pg4085.txt', 'pg2852.txt', 'pg12582.txt', 'pg1727.txt', 'pg2000.txt', 'pg120.txt', 'pg62119.txt', 'pg41287.txt', 'pg74.txt'}\n"
     ]
    }
   ],
   "source": [
    "def buscar_con_booleanos(query, inverted_index_df):\n",
    "    pd.set_option('display.max_rows', None)  # Mostrar todas las filas\n",
    "    pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
    "\n",
    "    query_parts = query.split()\n",
    "    result = None\n",
    "    \n",
    "    while query_parts:\n",
    "        token = query_parts.pop(0)\n",
    "        if token == 'AND':\n",
    "            operand1 = result\n",
    "            operand2 = set()\n",
    "            next_token = query_parts.pop(0)\n",
    "            if next_token in inverted_index_df.index:\n",
    "                operand2 = set(inverted_index_df.loc[next_token][inverted_index_df.loc[next_token] > 0].index)\n",
    "            result = operand1.intersection(operand2)\n",
    "        elif token == 'OR':\n",
    "            operand1 = result\n",
    "            operand2 = set()\n",
    "            next_token = query_parts.pop(0)\n",
    "            if next_token in inverted_index_df.index:\n",
    "                operand2 = set(inverted_index_df.loc[next_token][inverted_index_df.loc[next_token] > 0].index)\n",
    "            result = operand1.union(operand2)\n",
    "        elif token == 'NOT':\n",
    "            operand1 = result\n",
    "            operand2 = set()\n",
    "            next_token = query_parts.pop(0)\n",
    "            if next_token in inverted_index_df.index:\n",
    "                operand2 = set(inverted_index_df.loc[next_token][inverted_index_df.loc[next_token] > 0].index)\n",
    "            result = operand1.difference(operand2)\n",
    "        else:\n",
    "            result = set()\n",
    "            if token in inverted_index_df.index:\n",
    "                result = set(inverted_index_df.loc[token][inverted_index_df.loc[token] > 0].index)\n",
    "    \n",
    "    if result:\n",
    "        print(\"Documentos que cumplen con la consulta:\")\n",
    "        print(result)\n",
    "    else:\n",
    "        print(\"No se encontraron documentos que cumplan con la consulta.\")\n",
    "\n",
    "# Ejemplo de uso:\n",
    "query = \"william AND shakespear OR this\"\n",
    "buscar_con_booleanos(query, indice_invertido_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de30071-b35e-4ac5-be9c-2e8bc06ee1c1",
   "metadata": {},
   "source": [
    "# Interfaz de Usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a9369-f0df-428c-b716-65534142b573",
   "metadata": {},
   "source": [
    "\r\n",
    "En esta sección, implementamos una interfaz de usuario web para permitir a los usuarios realizar búsquedas en el índice invertido construido previamente. Los pasos específicos para la interfaz de usuario incluyen:\r\n",
    "\r\n",
    "1. **Instalación de Bibliotecas**: Utilizamos pip para instalar las bibliotecas necesarias, incluyendo Flask para el desarrollo del servidor web y Waitress para el servidor de producción.\r\n",
    "\r\n",
    "2. **Definición de Rutas**: Configuramos rutas en la aplicación Flask para manejar las solicitudes del cliente. La ruta principal carga la página HTML que contiene el formulario de búsqueda, mientras que la ruta `/search` procesa la solicitud de búsqueda y devuelve los resultados.\r\n",
    "\r\n",
    "3. **Carga del Índice Invertido**: Cargamos el índice invertido desde el archivo CSV generado previamente. Utilizamos pandas para cargar el índice invertido en un DataFrame para facilitar la manipulación y búsqueda de datos.\r\n",
    "\r\n",
    "4. **Página HTML**: Creamos una página HTML simple que contiene un formulario de búsqueda con un campo de entrada para que el usuario ingrese la palabra clave de búsqueda. Este formulario envía la palabra clave al servidor Flask cuando se envía.\r\n",
    "\r\n",
    "5. **Procesamiento de la Búsqueda**: En la ruta `/search`, recibimos la palabra clave ingresada por el usuario y verificamos si está presente en el índice invertido. Si la palabra clave está presente, devolvemos los archivos en los que aparece la palabra clave como resultado de la búsqueda. Si no está presente, mostramos un mensaje indicando que la palabra clave no está en el índice invertido.\r\n",
    "\r\n",
    "6. **Servidor en Ejecución**: Ejecutamos el servidor Flask para que esté disponible en una dirección IP y puerto específicos. Utilizamos Waitress para servir la aplicación Flask en un entorno de producción.\r\n",
    "\r\n",
    "Con esta interfaz de usuario, los usuarios pueden realizar búsquedas simples en el índice invertido y obtener resultados relevantes en función de las palabras clave ingresadas.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb9c016-f846-44eb-b6d5-90dbbb18a894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flask) (1.7.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flask) (6.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata>=3.6.0->flask) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Requirement already satisfied: gunicorn in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (22.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gunicorn) (23.2)\n",
      "Requirement already satisfied: waitress in c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask\n",
    "!pip install gunicorn\n",
    "!pip install waitress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925150e5-ad0f-4424-be9d-9752c1920fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wsgi.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile wsgi.py\n",
    "from busqueda import app as application\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    application.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e4050d-305b-4a01-8b05-55dc6cebc08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Servidor en ejecución en http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "from waitress import serve\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Cargar el índice invertido desde el archivo CSV\n",
    "indice_invertido_df = pd.read_csv('inverted_index.csv', index_col=0)\n",
    "\n",
    "# Ruta principal que carga la página HTML\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# Ruta para realizar la búsqueda de palabras en el índice invertido\n",
    "@app.route('/search')\n",
    "def search():\n",
    "    keyword = request.args.get('keyword')\n",
    "\n",
    "    # Verificar si la palabra está en el índice invertido\n",
    "    keyword = keyword.lower()  # Convertir la palabra a minúsculas para que coincida con el formato en el DataFrame\n",
    "    if keyword in indice_invertido_df.index:\n",
    "        # Obtener los archivos en los que aparece la palabra\n",
    "        files = indice_invertido_df.loc[keyword][indice_invertido_df.loc[keyword] > 0].index.tolist()\n",
    "        return jsonify({'files': files})\n",
    "    else:\n",
    "        return jsonify({'message': 'La palabra no está en el índice invertido'})\n",
    "\n",
    "# Ruta para realizar la búsqueda booleana\n",
    "@app.route('/boolean_search')\n",
    "def boolean_search():\n",
    "    query = request.args.get('query')\n",
    "    result = buscar_con_booleanos(query, indice_invertido_df)\n",
    "    return jsonify({'resultados': list(result)})\n",
    "\n",
    "# Función para buscar con booleanos\n",
    "def buscar_con_booleanos(query, inverted_index_df):\n",
    "    query_parts = query.split()\n",
    "    result = None\n",
    "    \n",
    "    while query_parts:\n",
    "        token = query_parts.pop(0)\n",
    "        if token == 'AND':\n",
    "            operand1 = result\n",
    "            operand2 = set()\n",
    "            next_token = query_parts.pop(0)\n",
    "            if next_token in inverted_index_df.index:\n",
    "                operand2 = set(inverted_index_df.loc[next_token][inverted_index_df.loc[next_token] > 0].index)\n",
    "            result = operand1.intersection(operand2)\n",
    "        elif token == 'OR':\n",
    "            operand1 = result\n",
    "            operand2 = set()\n",
    "            next_token = query_parts.pop(0)\n",
    "            if next_token in inverted_index_df.index:\n",
    "                operand2 = set(inverted_index_df.loc[next_token][inverted_index_df.loc[next_token] > 0].index)\n",
    "            result = operand1.union(operand2)\n",
    "        elif token == 'NOT':\n",
    "            operand1 = result\n",
    "            operand2 = set()\n",
    "            next_token = query_parts.pop(0)\n",
    "            if next_token in inverted_index_df.index:\n",
    "                operand2 = set(inverted_index_df.loc[next_token][inverted_index_df.loc[next_token] > 0].index)\n",
    "            result = operand1.difference(operand2)\n",
    "        else:\n",
    "            result = set()\n",
    "            if token in inverted_index_df.index:\n",
    "                result = set(inverted_index_df.loc[token][inverted_index_df.loc[token] > 0].index)\n",
    "    \n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    host = '127.0.0.1'\n",
    "    port = 5000\n",
    "    print(f\"Servidor en ejecución en http://{host}:{port}\")\n",
    "    serve(app, host=host, port=port)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
